{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Random Forest and Fidex rule generation for obesity risk classification\n",
    "\n",
    "**Introduction:**\n",
    "\n",
    "Welcome to HES-Xplain, our interactive platform designed to facilitate explainable artificial intelligence (XAI) techniques. In this use case, we dive into obesity risk classification and showcase another application example of explainability techniques.\n",
    "\n",
    "This notebook is an alternative to the [`Exploring Dimlp and Fidex rule generation for breast cancer classification`](TODO). It aims to be similar but aims to use a different dataset and training model to show the versatility of our explainability tools.  In addition, we will cover how to pre-process a dataset that is not initially usable by a model and convert it to an exploitable dataset.\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "    1. Observe a different use case where XAI can be used.\n",
    "    2. Understand how to pre-process data.\n",
    "    3. Understand how to use Dimlp and Fidex.\n",
    "    4. Showcase the versatility of HES-Xplain using a different dataset and training model.\n",
    "    5. Provide practical insights into applying Random Forests and Fidex to breast cancer classifiers through an interactive notebook.\n",
    "    6. Foster a community of XAI enthusiasts and practitioners.\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "    1. Dataset and Problem Statement.\n",
    "    2. Load and pre-process the dataset.\n",
    "    3. Train the Model.\n",
    "    4. Local rules generation - Fidex.\n",
    "    5. Global ruleSet generation - FidexGlo.\n",
    "    6. Conclusion.\n",
    "    7. References.\n",
    "\n",
    "Through this use case, we aim to show the users the potential of Random Forests and Fidex as tools for transparent and interpretable classification. With HES-Xplain, we make XAI accessible, helping users build trust in their models and make informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Google Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section prepares the notebook for use with Google Colaboratory. If applicable, change the following variable to True:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab compatibility\n",
    "use_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_colab:\n",
    "    # ensure the directory is empty\n",
    "    !rm -rf * .config\n",
    "\n",
    "    !# install codebase from GitHub\n",
    "    !git clone --no-checkout https://github.com/HES-XPLAIN/notebooks.git --depth=1 .\n",
    "    !git config core.sparseCheckout true\n",
    "    !git sparse-checkout set --cone\n",
    "    !git sparse-checkout add use_case_dimlpfidex\n",
    "    !git sparse-checkout reapply\n",
    "    !git checkout main\n",
    "\n",
    "    # adjust folder structure\n",
    "    !mv use_case_dimlpfidex/* .\n",
    "    !rm -rf use_case_dimlpfidex/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Problem Statement\n",
    "The dataset we'll be working with is called the [obesity or CVD risk](https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster/data) and is accessible on [Kaggle](https://www.kaggle.com). It comprises 2111 records of anonymized data concerning South American individuals and their dietary habits. In this notebook, our focus is on another medical challenge: classifying the risk of obesity based on various factors. These factors, drawn from the dataset, are outlined below with their original names:\n",
    "\n",
    "| **Full name**                             | **Used label** |                                                        **Values/Ranges**                                                       | **Description**                                                                     |\n",
    "|-------------------------------------------|:--------------:|:------------------------------------------------------------------------------------------------------------------------------:|-------------------------------------------------------------------------------------|\n",
    "| Gender                                    |     Gender     |                                                          Male, Female                                                          | Person's biological gender                                                          |\n",
    "| Age                                       |       Age      |                                                             [14:61]                                                            | Person's age in years                                                               |\n",
    "| Height                                    |     Height     |                                                           [1.45:1.98]                                                          | Person's height in meters                                                           |\n",
    "| Weight                                    |     Weight     |                                                            [39:173]                                                            | Person's weight in kilograms                                                        |\n",
    "| Family history with overweight            |      FHWO      |                                                             yes, no                                                            | Whether the person has at least one sibling that suffers or suffered of overweight  |\n",
    "| Frequent consumption of high-caloric food |      FAVC      |                                                             yes, no                                                            | Whether the person is frequently consuming high-caloric food                        |\n",
    "| Frequency of consumption of vegetables    |      FCVC      |                                                              [1:3]                                                             | Leveled frequency of consumption of vegetables                                      |\n",
    "| Number of main meals                      |       NCP      |                                                              [1:4]                                                             | Person's number of main meals during a day                                          |\n",
    "| Consumption of food between meals         |      CAEC      |                                                no, sometimes, frequently, always                                               | Person's consumption of food between main meals frequency per day                   |\n",
    "| Smoker or not                             |      SMOKE     |                                                             yes, no                                                            | Whether the person smokes                                                           |\n",
    "| Consumption of water daily                |      CH20      |                                                              [1:3]                                                             | Numeric representation of water consumption frequency per day                       |\n",
    "| Calories consumption monitoring           |       SCC      |                                                             yes, no                                                            | Whether the person is monitoring his daily calories intake                          |\n",
    "| Physical activity frequency               |       FAF      |                                                              [0:3]                                                             | Numeric representation of physical activity frequency per week                      |\n",
    "| Time using technology devices             |       TUE      |                                                              [0:2]                                                             | Numeric representation of electronic devices use frequency per day                  |\n",
    "| Consumption of alcohol                    |      CALC      |                                                no, sometimes, frequently, always                                               | Frequency of alcohol consumption                                                    |\n",
    "| Transportation used                       |     MTRANS     |                                   Public_Transportation, Automobile, Bike, Motorbike, Walking                                  | Medium usually used to transit                                                      |\n",
    "| Obesity level deducted                    |       OLD      | Insufficient_Weight, Normal_Weight, Overweight_Level_I, Overweight_Level_II, Obesity_Type_I, Obesity_Type_II, Obesity_Type_III | Obesity level observed according to the interpretation of the person's BMI          |\n",
    "\n",
    "Our goal is to train a random forest model to classify the obesity level based on the other features. To achieve this, we will need to modify the original dataset to convert several features into a format that is suitable for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pre-process the dataset\n",
    "Here we start by simplifying the names of the columns and taking a look at the CSV file containing the raw data:\n",
    "\n",
    ">**`Pandas` version must be higher than 2.0 and less than 3.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Female</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Always</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.721854</td>\n",
       "      <td>52.514302</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.339980</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>1.884138</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>Male</td>\n",
       "      <td>25.822348</td>\n",
       "      <td>1.766626</td>\n",
       "      <td>114.187096</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.075321</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.144838</td>\n",
       "      <td>no</td>\n",
       "      <td>1.501754</td>\n",
       "      <td>0.276319</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.649792</td>\n",
       "      <td>1.685045</td>\n",
       "      <td>81.022119</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.756622</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>1.606076</td>\n",
       "      <td>no</td>\n",
       "      <td>0.432973</td>\n",
       "      <td>1.749586</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight FHWO FAVC      FCVC       NCP  \\\n",
       "303   Female  16.000000  1.570000   49.000000   no  yes  2.000000  4.000000   \n",
       "639     Male  18.000000  1.721854   52.514302  yes  yes  2.339980  3.000000   \n",
       "20      Male  22.000000  1.650000   80.000000  yes   no  2.000000  3.000000   \n",
       "1717    Male  25.822348  1.766626  114.187096  yes  yes  2.075321  3.000000   \n",
       "1168    Male  22.649792  1.685045   81.022119  yes  yes  2.000000  2.756622   \n",
       "\n",
       "           CAEC SMOKE      CH2O SCC       FAF       TUE       CALC  \\\n",
       "303      Always    no  2.000000  no  0.000000  1.000000  Sometimes   \n",
       "639   Sometimes    no  2.000000  no  0.027433  1.884138  Sometimes   \n",
       "20    Sometimes    no  2.000000  no  3.000000  2.000000         no   \n",
       "1717  Sometimes    no  2.144838  no  1.501754  0.276319  Sometimes   \n",
       "1168  Sometimes    no  1.606076  no  0.432973  1.749586         no   \n",
       "\n",
       "                     MTRANS                  OLD  \n",
       "303   Public_Transportation        Normal_Weight  \n",
       "639   Public_Transportation  Insufficient_Weight  \n",
       "20                  Walking  Overweight_Level_II  \n",
       "1717  Public_Transportation      Obesity_Type_II  \n",
       "1168  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dimlpfidex.fidex import fidex, fidexGloRules, fidexGloStats\n",
    "from trainings.randForestsTrn import randForestsTrn as randomForest\n",
    "\n",
    "# utility function to preview a file entirely or only the first `nlines` lines\n",
    "def previewFile(filepath, nlines=-1):\n",
    "    lines = \"\"\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        if nlines == -1:\n",
    "            for line in f:\n",
    "                lines += line\n",
    "        else:\n",
    "            for _ in range(nlines):\n",
    "                try:\n",
    "                    lines += next(f)\n",
    "                except StopIteration:\n",
    "                    break\n",
    "    print(lines)\n",
    "\n",
    "dataset = pd.read_csv(\"data/OCDDataset/ObesityDataSet.csv\")\n",
    "\n",
    "# reducing labels names size\n",
    "dataset.rename(\n",
    "    columns={\n",
    "        \"family_history_with_overweight\": \"FHWO\",\n",
    "        \"NObeyesdad\": \"OLD\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# shuffle the entire dataset\n",
    "dataset = dataset.sample(frac=1)\n",
    "nrows = int(dataset.shape[0] * 0.1)\n",
    "dataset = dataset.iloc[:nrows, :]\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the dataset more compatible with machine learning, we'll start by converting features that have \"yes\" or \"no\" values into their boolean representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10785/2158653555.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset[\"FHWO\"] = dataset[\"FHWO\"].replace(strToBinDict).astype(\"int8\")\n",
      "/tmp/ipykernel_10785/2158653555.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset[\"FAVC\"] = dataset[\"FAVC\"].replace(strToBinDict).astype(\"int8\")\n",
      "/tmp/ipykernel_10785/2158653555.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset[\"SMOKE\"] = dataset[\"SMOKE\"].replace(strToBinDict).astype(\"int8\")\n",
      "/tmp/ipykernel_10785/2158653555.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset[\"SCC\"] = dataset[\"SCC\"].replace(strToBinDict).astype(\"int8\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Female</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Always</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.721854</td>\n",
       "      <td>52.514302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.339980</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>1.884138</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>Male</td>\n",
       "      <td>25.822348</td>\n",
       "      <td>1.766626</td>\n",
       "      <td>114.187096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.075321</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>2.144838</td>\n",
       "      <td>0</td>\n",
       "      <td>1.501754</td>\n",
       "      <td>0.276319</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.649792</td>\n",
       "      <td>1.685045</td>\n",
       "      <td>81.022119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.756622</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>1.606076</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432973</td>\n",
       "      <td>1.749586</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight  FHWO  FAVC      FCVC       NCP  \\\n",
       "303   Female  16.000000  1.570000   49.000000     0     1  2.000000  4.000000   \n",
       "639     Male  18.000000  1.721854   52.514302     1     1  2.339980  3.000000   \n",
       "20      Male  22.000000  1.650000   80.000000     1     0  2.000000  3.000000   \n",
       "1717    Male  25.822348  1.766626  114.187096     1     1  2.075321  3.000000   \n",
       "1168    Male  22.649792  1.685045   81.022119     1     1  2.000000  2.756622   \n",
       "\n",
       "           CAEC  SMOKE      CH2O  SCC       FAF       TUE       CALC  \\\n",
       "303      Always      0  2.000000    0  0.000000  1.000000  Sometimes   \n",
       "639   Sometimes      0  2.000000    0  0.027433  1.884138  Sometimes   \n",
       "20    Sometimes      0  2.000000    0  3.000000  2.000000         no   \n",
       "1717  Sometimes      0  2.144838    0  1.501754  0.276319  Sometimes   \n",
       "1168  Sometimes      0  1.606076    0  0.432973  1.749586         no   \n",
       "\n",
       "                     MTRANS                  OLD  \n",
       "303   Public_Transportation        Normal_Weight  \n",
       "639   Public_Transportation  Insufficient_Weight  \n",
       "20                  Walking  Overweight_Level_II  \n",
       "1717  Public_Transportation      Obesity_Type_II  \n",
       "1168  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strToBinDict = {\"yes\": 1, \"no\": 0}\n",
    "\n",
    "dataset[\"FHWO\"] = dataset[\"FHWO\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"FAVC\"] = dataset[\"FAVC\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"SMOKE\"] = dataset[\"SMOKE\"].replace(strToBinDict).astype(\"int8\")\n",
    "dataset[\"SCC\"] = dataset[\"SCC\"].replace(strToBinDict).astype(\"int8\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the `CAEC` and `CALC` columns, which contain the values \"Always,\" \"Frequently,\" \"Sometimes,\" and \"no,\" into a numerical scale from 0.00 to 1.00 based on their frequency. Here's the conversion table:\n",
    "\n",
    "| **Adjective** | **Conversion Value** |\n",
    "|---------------|:--------------------:|\n",
    "| Always        |         1.00         |\n",
    "| Frequently    |         0.66         |\n",
    "| Sometimes     |         0.33         |\n",
    "| no            |         0.00         |\n",
    "\n",
    "We'll apply a similar procedure as before to achieve the conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10785/331685197.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset[\"CAEC\"] = dataset[\"CAEC\"].replace(adjToValDict).astype('float64')\n",
      "/tmp/ipykernel_10785/331685197.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset[\"CALC\"] = dataset[\"CALC\"].replace(adjToValDict).astype('float64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>OLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Female</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Male</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.721854</td>\n",
       "      <td>52.514302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.339980</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>1.884138</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Insufficient_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>Male</td>\n",
       "      <td>25.822348</td>\n",
       "      <td>1.766626</td>\n",
       "      <td>114.187096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.075321</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.144838</td>\n",
       "      <td>0</td>\n",
       "      <td>1.501754</td>\n",
       "      <td>0.276319</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.649792</td>\n",
       "      <td>1.685045</td>\n",
       "      <td>81.022119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.756622</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.606076</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432973</td>\n",
       "      <td>1.749586</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender        Age    Height      Weight  FHWO  FAVC      FCVC       NCP  \\\n",
       "303   Female  16.000000  1.570000   49.000000     0     1  2.000000  4.000000   \n",
       "639     Male  18.000000  1.721854   52.514302     1     1  2.339980  3.000000   \n",
       "20      Male  22.000000  1.650000   80.000000     1     0  2.000000  3.000000   \n",
       "1717    Male  25.822348  1.766626  114.187096     1     1  2.075321  3.000000   \n",
       "1168    Male  22.649792  1.685045   81.022119     1     1  2.000000  2.756622   \n",
       "\n",
       "      CAEC  SMOKE      CH2O  SCC       FAF       TUE  CALC  \\\n",
       "303   1.00      0  2.000000    0  0.000000  1.000000  0.33   \n",
       "639   0.33      0  2.000000    0  0.027433  1.884138  0.33   \n",
       "20    0.33      0  2.000000    0  3.000000  2.000000  0.00   \n",
       "1717  0.33      0  2.144838    0  1.501754  0.276319  0.33   \n",
       "1168  0.33      0  1.606076    0  0.432973  1.749586  0.00   \n",
       "\n",
       "                     MTRANS                  OLD  \n",
       "303   Public_Transportation        Normal_Weight  \n",
       "639   Public_Transportation  Insufficient_Weight  \n",
       "20                  Walking  Overweight_Level_II  \n",
       "1717  Public_Transportation      Obesity_Type_II  \n",
       "1168  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjToValDict = {\"Always\": 1.0, \"Frequently\": 0.66, \"Sometimes\": 0.33, \"no\": 0.0}\n",
    "\n",
    "dataset[\"CAEC\"] = dataset[\"CAEC\"].replace(adjToValDict).astype('float64')\n",
    "dataset[\"CALC\"] = dataset[\"CALC\"].replace(adjToValDict).astype('float64')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll address three additional columns named `Gender`, `MTRANS`, and `OLD`, which currently contain non-numerical values. These values represent individual options and cannot be quantified using a scale like before. Instead, we'll encode them using a technique called \"one-hot encoding\". This technique will assign a binary value to each option, representing its presence or absence. \n",
    "\n",
    "Let's proceed with applying one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FHWO</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>...</th>\n",
       "      <th>MTRANS_Motorbike</th>\n",
       "      <th>MTRANS_Public_Transportation</th>\n",
       "      <th>MTRANS_Walking</th>\n",
       "      <th>OLD_Insufficient_Weight</th>\n",
       "      <th>OLD_Normal_Weight</th>\n",
       "      <th>OLD_Obesity_Type_I</th>\n",
       "      <th>OLD_Obesity_Type_II</th>\n",
       "      <th>OLD_Obesity_Type_III</th>\n",
       "      <th>OLD_Overweight_Level_I</th>\n",
       "      <th>OLD_Overweight_Level_II</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.721854</td>\n",
       "      <td>52.514302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.339980</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.822348</td>\n",
       "      <td>1.766626</td>\n",
       "      <td>114.187096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.075321</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.649792</td>\n",
       "      <td>1.685045</td>\n",
       "      <td>81.022119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.756622</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender_Female  Gender_Male        Age    Height      Weight  FHWO  FAVC  \\\n",
       "303               1            0  16.000000  1.570000   49.000000     0     1   \n",
       "639               0            1  18.000000  1.721854   52.514302     1     1   \n",
       "20                0            1  22.000000  1.650000   80.000000     1     0   \n",
       "1717              0            1  25.822348  1.766626  114.187096     1     1   \n",
       "1168              0            1  22.649792  1.685045   81.022119     1     1   \n",
       "\n",
       "          FCVC       NCP  CAEC  ...  MTRANS_Motorbike  \\\n",
       "303   2.000000  4.000000  1.00  ...                 0   \n",
       "639   2.339980  3.000000  0.33  ...                 0   \n",
       "20    2.000000  3.000000  0.33  ...                 0   \n",
       "1717  2.075321  3.000000  0.33  ...                 0   \n",
       "1168  2.000000  2.756622  0.33  ...                 0   \n",
       "\n",
       "      MTRANS_Public_Transportation  MTRANS_Walking  OLD_Insufficient_Weight  \\\n",
       "303                              1               0                        0   \n",
       "639                              1               0                        1   \n",
       "20                               0               1                        0   \n",
       "1717                             1               0                        0   \n",
       "1168                             1               0                        0   \n",
       "\n",
       "      OLD_Normal_Weight  OLD_Obesity_Type_I  OLD_Obesity_Type_II  \\\n",
       "303                   1                   0                    0   \n",
       "639                   0                   0                    0   \n",
       "20                    0                   0                    0   \n",
       "1717                  0                   0                    1   \n",
       "1168                  0                   0                    0   \n",
       "\n",
       "      OLD_Obesity_Type_III  OLD_Overweight_Level_I  OLD_Overweight_Level_II  \n",
       "303                      0                       0                        0  \n",
       "639                      0                       0                        0  \n",
       "20                       0                       0                        1  \n",
       "1717                     0                       0                        0  \n",
       "1168                     0                       0                        1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genderCols = pd.get_dummies(dataset[\"Gender\"], prefix=\"Gender\",prefix_sep='_', dtype='int8')\n",
    "mtransCols = pd.get_dummies(dataset[\"MTRANS\"], prefix=\"MTRANS\",prefix_sep='_', dtype='int8')\n",
    "oldCols = pd.get_dummies(dataset[\"OLD\"], prefix=\"OLD\",prefix_sep='_', dtype='int8')\n",
    "dataset = pd.concat([genderCols, dataset.iloc[:,:16], mtransCols,  dataset.iloc[:,16:], oldCols], axis=1)\n",
    "dataset.drop([\"Gender\", \"MTRANS\", \"OLD\"], axis=1, inplace=True)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataset is prepared to be used, let's ensure the data's integrity by verifying some information, starting with a general overview of our columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 211 entries, 303 to 469\n",
      "Data columns (total 27 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Gender_Female                 211 non-null    int8   \n",
      " 1   Gender_Male                   211 non-null    int8   \n",
      " 2   Age                           211 non-null    float64\n",
      " 3   Height                        211 non-null    float64\n",
      " 4   Weight                        211 non-null    float64\n",
      " 5   FHWO                          211 non-null    int8   \n",
      " 6   FAVC                          211 non-null    int8   \n",
      " 7   FCVC                          211 non-null    float64\n",
      " 8   NCP                           211 non-null    float64\n",
      " 9   CAEC                          211 non-null    float64\n",
      " 10  SMOKE                         211 non-null    int8   \n",
      " 11  CH2O                          211 non-null    float64\n",
      " 12  SCC                           211 non-null    int8   \n",
      " 13  FAF                           211 non-null    float64\n",
      " 14  TUE                           211 non-null    float64\n",
      " 15  CALC                          211 non-null    float64\n",
      " 16  MTRANS_Automobile             211 non-null    int8   \n",
      " 17  MTRANS_Motorbike              211 non-null    int8   \n",
      " 18  MTRANS_Public_Transportation  211 non-null    int8   \n",
      " 19  MTRANS_Walking                211 non-null    int8   \n",
      " 20  OLD_Insufficient_Weight       211 non-null    int8   \n",
      " 21  OLD_Normal_Weight             211 non-null    int8   \n",
      " 22  OLD_Obesity_Type_I            211 non-null    int8   \n",
      " 23  OLD_Obesity_Type_II           211 non-null    int8   \n",
      " 24  OLD_Obesity_Type_III          211 non-null    int8   \n",
      " 25  OLD_Overweight_Level_I        211 non-null    int8   \n",
      " 26  OLD_Overweight_Level_II       211 non-null    int8   \n",
      "dtypes: float64(10), int8(17)\n",
      "memory usage: 21.6 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check that there are no missing values in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender_Female                   0\n",
       "Gender_Male                     0\n",
       "Age                             0\n",
       "Height                          0\n",
       "Weight                          0\n",
       "FHWO                            0\n",
       "FAVC                            0\n",
       "FCVC                            0\n",
       "NCP                             0\n",
       "CAEC                            0\n",
       "SMOKE                           0\n",
       "CH2O                            0\n",
       "SCC                             0\n",
       "FAF                             0\n",
       "TUE                             0\n",
       "CALC                            0\n",
       "MTRANS_Automobile               0\n",
       "MTRANS_Motorbike                0\n",
       "MTRANS_Public_Transportation    0\n",
       "MTRANS_Walking                  0\n",
       "OLD_Insufficient_Weight         0\n",
       "OLD_Normal_Weight               0\n",
       "OLD_Obesity_Type_I              0\n",
       "OLD_Obesity_Type_II             0\n",
       "OLD_Obesity_Type_III            0\n",
       "OLD_Overweight_Level_I          0\n",
       "OLD_Overweight_Level_II         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll ensure that there are no duplicated records in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop_duplicates()\n",
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to split our dataset into two distinct datasets, one for the training process and the other for the testing process. Then, write them in separate files to allow them to be used by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of records:\t210\n",
      "Number of records for training:\t157\n",
      "Number of records for testing:\t53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nRecords = dataset.shape[0]\n",
    "trainSplit = int(0.75 * nRecords)\n",
    "\n",
    "trainds = dataset.iloc[:trainSplit, :]\n",
    "testds = dataset.iloc[trainSplit:, :]\n",
    "\n",
    "# We are writing TXT format to comply with our random forest algorithm\n",
    "rootDir = \"data/OCDDataset/\"\n",
    "trainDataFile = \"train_dataset.txt\"\n",
    "testDataFile = \"test_dataset.txt\"\n",
    "\n",
    "trainds.to_csv(rootDir + trainDataFile, header=False, index=False)\n",
    "testds.to_csv(rootDir + testDataFile, header=False, index=False)\n",
    "\n",
    "print(\n",
    "f\"\"\"\n",
    "Total number of records:\\t{nRecords}\n",
    "Number of records for training:\\t{trainds.shape[0]}\n",
    "Number of records for testing:\\t{testds.shape[0]}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is ready and checked for any missing or duplicate values, we're all set to move on to the next step. In the upcoming chapter, we'll use our prepared dataset to train our Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Here is the main part of our task: training the model. To do so, we're going to use a type of model called random forests.\n",
    "\n",
    "In this case, we are going to use our Python program called [randomForest](https://hes-xplain.github.io/documentation/algorithms/training-methods/randforeststrn/). Let's begin with printing the program help message to observe every option available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: \n",
      "--train_data_file <str> --test_data_file <str> --nb_attributes <int [1,inf[> --nb_classes <int [1,inf[> [-h, --help] [--json_config_file <str>] [--root_folder <str>] [--train_class_file <str>] [--test_class_file <str>] [--train_pred_outfile <str>] [--test_pred_outfile <str>] [--stats_file <str>] [--console_file <str>] [--rules_outfile <str>] [--n_estimators <int [1,inf[>] [--criterion <{gini, entropy, log_loss}>] [--max_depth <int [1,inf[>] [--min_samples_split <int [2,inf[ U float]0,1.0]>] [--min_samples_leaf <int [1,inf[ U float]0,1[>] [--min_weight_fraction_leaf <float [0,0.5]>] [--max_features <{sqrt, log2, all, float ]0,1[, int [1,inf[}>] [--max_leaf_nodes <int [2,inf[>] [--min_impurity_decrease <float [0,inf[>] [--bootstrap <bool>] [--oob_score <bool>] [--n_jobs <int>] [--seed <{int [0,inf[}>] [--verbose <int [0,inf[>] [--warm_start <bool>] [--class_weight <{balanced, balanced_subsample, dict}>] [--ccp_alpha <float [0,inf[>] [--max_samples <int [1,inf[ U float]0,1.0]>]\n",
      "\n",
      "This is a parser for randForestsTrn\n",
      "\n",
      "\n",
      "Parameters:\n",
      "\n",
      "  ---------------------------------------------------------------------\n",
      "\n",
      "  Warning! The files are located with respect to the root folder dimlpfidex.\n",
      "\n",
      "  The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Required parameters:\n",
      "\n",
      "  --train_data_file <str>                                   Path to the file containing the train portion of the dataset\n",
      "  --test_data_file <str>                                    Path to the file containing the test portion of the dataset\n",
      "  --nb_attributes <int [1,inf[>                             Number of attributes in the dataset\n",
      "  --nb_classes <int [1,inf[>                                Number of classes in the dataset\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  Optional parameters:\n",
      "\n",
      "  -h --help                                                 show this help message and exit\n",
      "  --json_config_file <str>                                  Path to the JSON file that configures all parameters. If used, this must be the sole\n",
      "                                                            argument and must specify the file's relative path\n",
      "  --root_folder <str>                                       Path to the folder, based on main default folder dimlpfidex, containing all used files and\n",
      "                                                            where generated files will be saved. If a file name is specified with another option, its\n",
      "                                                            path will be relative to this root folder> (default: \"\")\n",
      "  --train_class_file <str>                                  Path to the file containing the train true classes of the dataset, mandatory if classes\n",
      "                                                            are not specified in train_data_file\n",
      "  --test_class_file <str>                                   Path to the file containing the test true classes of the dataset, mandatory if classes are\n",
      "                                                            not specified in test_data_file\n",
      "  --train_pred_outfile <str>                                Path to the file where the train predictions will be stored (default: predTrain.out)\n",
      "  --test_pred_outfile <str>                                 Path to the file where the test predictions will be stored (default: predTest.out)\n",
      "  --stats_file <str>                                        Path to the file where the train and test accuracy will be stored (default: stats.txt)\n",
      "  --console_file <str>                                      Path to the file where the terminal output will be redirected. If not specified, all\n",
      "                                                            output will be shown on your terminal\n",
      "  --rules_outfile <str>                                     Path to the file where the random forests output rules will be stored (default:\n",
      "                                                            RF_rules.rls)\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "  RF parameters (optional):\n",
      "\n",
      "  --n_estimators <int [1,inf[>                              Number of generated trees in the forest (default: 100)\n",
      "  --criterion <{gini, entropy, log_loss}>                   Function to measure split quality (default: gini)\n",
      "  --max_depth <int [1,inf[>                                 Maximum depth of the tree\n",
      "  --min_samples_split <int [2,inf[ U float]0,1.0]>          Minimum number of samples required to split an internal node, if float, it is a fraction\n",
      "                                                            of the number of samples. (default: 2)\n",
      "  --min_samples_leaf <int [1,inf[ U float]0,1[>             Minimum number of samples required to be at a leaf node, if float, it is a fraction of the\n",
      "                                                            number of samples (default: 1)\n",
      "  --min_weight_fraction_leaf <float [0,0.5]>                Minimum weighted fraction of the sum total of input samples weights required to be at a\n",
      "                                                            leaf node (default: 0.0)\n",
      "  --max_features <{sqrt, log2, all, float ]0,1[, int [1,inf[}>\n",
      "                                                            Number of features to consider when looking for the best splitif float, it is a fraction\n",
      "                                                            of the number of features. 1 stands for 1 feature, for all features put 'all', not 1.0\n",
      "                                                            (default: sqrt)\n",
      "  --max_leaf_nodes <int [2,inf[>                            Grow trees with max_leaf_nodes in best-first fashion\n",
      "  --min_impurity_decrease <float [0,inf[>                   A node will be split if this split induces a decrease of the impurity greater than or\n",
      "                                                            equal to this value (default: 0.0)\n",
      "  --bootstrap <bool>                                        Whether bootstrap samples are used when building trees (default: True)\n",
      "  --oob_score <bool>                                        Whether to use out-of-bag samples to estimate the generalization score (default: False)\n",
      "  --n_jobs <int>                                            Number of jobs to run in parallel, -1 = using all processors (default: 1)\n",
      "  --seed <{int [0,inf[}>                                    Seed for random number generation\n",
      "  --verbose <int [0,inf[>                                   Controls the verbosity when fitting and predicting (default: 0)\n",
      "  --warm_start <bool>                                       Whether to reuse the solution of the previous call to fit and add more estimators to the\n",
      "                                                            ensemble (default: False)\n",
      "  --class_weight <{balanced, balanced_subsample, dict}>     Class balance, for exemple with a dictionnary and 2 classes : {0:1.2, 1:3.5}\n",
      "  --ccp_alpha <float [0,inf[>                               Complexity parameter used for Minimal Cost-Complexity Pruning (default: 0.0)\n",
      "  --max_samples <int [1,inf[ U float]0,1.0]>                Number of samples to draw to train each base estimator for bootstrap, if float, it is a\n",
      "                                                            fraction of the number of samples\n",
      "\n",
      "  ----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "randForestsTrn('--train_data_file datanormTrain.txt --train_class_file dataclass2Train.txt --test_data_file datanormTest.txt --test_class_file dataclass2Test.txt --stats_file rf/stats.txt --train_pred_outfile rf/predTrain.out --test_pred_outfile rf/predTest.out --rules_outfile rf/RF_rules.rls --nb_attributes 16 --nb_classes 2 --root_folder dimlp/datafiles')\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = randomForest(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output reveals various options. Among these, we'll focus on the required parameters (and the `--root_folder` for convenience). Since we've already generated the train and test data files in the previous chapter, our next step is to determine the number of attributes and classes. As the original class is denoted by `OLD`, post one-hot encoding, we need to count the number of labels prefixed with `OLD_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# attributes:\t20\n",
      "# classes:\t7\n"
     ]
    }
   ],
   "source": [
    "labels = list(dataset.columns)\n",
    "\n",
    "nclasses = sum(1 for label in labels if label.startswith(\"OLD_\"))\n",
    "nattributes = len(labels) - nclasses\n",
    "attributesFile = \"attributes_file.txt\" \n",
    "\n",
    "\n",
    "with open(rootDir+attributesFile, 'w') as f:\n",
    "    for label in dataset.columns:\n",
    "        f.write(label+'\\n')\n",
    "\n",
    "print(f\"# attributes:\\t{nattributes}\\n# classes:\\t{nclasses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, let's gather the elements we have to run the model:\n",
    "\n",
    "| **Parameter name** | **Input**           |\n",
    "|--------------------|:-------------------:|\n",
    "| --root_folder      | data/OCDDataset/    |\n",
    "| --train_data_file  | train_dataset.txt   |\n",
    "| --test_data_file   | test_dataset.txt    |\n",
    "| --nb_attributes    | 20                  |\n",
    "| --nb_classes       | 7                   |\n",
    "\n",
    "<br>\n",
    "With these parameters in place, we can proceed to run our random forest model, allowing the remaining options to be determined by their default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - root_folder                                                   data/OCDDataset/\n",
      " - train_data_file                                               data/OCDDataset/train_dataset.txt\n",
      " - test_data_file                                                data/OCDDataset/test_dataset.txt\n",
      " - nb_attributes                                                 20\n",
      " - nb_classes                                                    7\n",
      " - train_pred_outfile                                            data/OCDDataset/predTrain.out\n",
      " - test_pred_outfile                                             data/OCDDataset/predTest.out\n",
      " - stats_file                                                    data/OCDDataset/stats.txt\n",
      " - rules_outfile                                                 data/OCDDataset/RF_rules.rls\n",
      " - n_estimators                                                  100\n",
      " - criterion                                                     gini\n",
      " - min_samples_split                                             2\n",
      " - min_samples_leaf                                              1\n",
      " - min_weight_fraction_leaf                                      0.0\n",
      " - max_features                                                  sqrt\n",
      " - min_impurity_decrease                                         0.0\n",
      " - bootstrap                                                     True\n",
      " - oob_score                                                     False\n",
      " - n_jobs                                                        1\n",
      " - verbose                                                       0\n",
      " - warm_start                                                    False\n",
      " - ccp_alpha                                                     0.0\n",
      "End of Parameters list. \n",
      "\n",
      "Training accuracy : 100%.\n",
      "Testing accuracy : 81.132075%.\n",
      "\n",
      "Full execution time = 0.267795 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --test_data_file {testDataFile} \n",
    "        --nb_attributes {nattributes} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "randomForest(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm ended and generated a `rule_outfile` file. It contains all rules generated by each tree from the random forest. Lets visualize some of the first tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Tree 1\n",
      "-------------------\n",
      "Rule 1: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4<=105.48030090332031 X4<=74.0 X15<=0.16500000655651093 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 2: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4<=105.48030090332031 X4<=74.0 X15>0.16500000655651093 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 3: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4<=105.48030090332031 X4>74.0 X2<=22.877116203308105 X3<=1.7013825178146362 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 4: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4<=105.48030090332031 X4>74.0 X2<=22.877116203308105 X3>1.7013825178146362 X4<=94.02547836303711 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 5: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4<=105.48030090332031 X4>74.0 X2<=22.877116203308105 X3>1.7013825178146362 X4>94.02547836303711 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 6: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4<=105.48030090332031 X4>74.0 X2>22.877116203308105 X13<=1.260919988155365 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 7: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4<=105.48030090332031 X4>74.0 X2>22.877116203308105 X13>1.260919988155365 X3<=1.6929355263710022 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 8: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4<=105.48030090332031 X4>74.0 X2>22.877116203308105 X13>1.260919988155365 X3>1.6929355263710022 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 9: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7<=2.7991230487823486 X4>105.48030090332031 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 10: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7>2.7991230487823486 X12<=0.5 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 11: X0<=0.5 X8<=3.0478315353393555 X8<=2.9513829946517944 X7>2.7991230487823486 X12>0.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 12: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15<=0.16500000655651093 X6<=0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 13: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15<=0.16500000655651093 X6>0.5 X2<=42.72359848022461 X16<=0.5 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 14: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15<=0.16500000655651093 X6>0.5 X2<=42.72359848022461 X16>0.5 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 15: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15<=0.16500000655651093 X6>0.5 X2>42.72359848022461 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 16: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15>0.16500000655651093 X14<=0.869841992855072 X13<=1.0562520027160645 X7<=2.025309443473816 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 17: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15>0.16500000655651093 X14<=0.869841992855072 X13<=1.0562520027160645 X7>2.025309443473816 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 18: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15>0.16500000655651093 X14<=0.869841992855072 X13>1.0562520027160645 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 19: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15>0.16500000655651093 X14>0.869841992855072 X16<=0.5 X4<=59.0 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 20: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15>0.16500000655651093 X14>0.869841992855072 X16<=0.5 X4>59.0 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 21: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15>0.16500000655651093 X14>0.869841992855072 X16>0.5 X3<=1.818472981452942 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 22: X0<=0.5 X8<=3.0478315353393555 X8>2.9513829946517944 X15>0.16500000655651093 X14>0.869841992855072 X16>0.5 X3>1.818472981452942 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 23: X0<=0.5 X8>3.0478315353393555 X5<=0.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 24: X0<=0.5 X8>3.0478315353393555 X5>0.5 X8<=3.561134457588196 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 25: X0<=0.5 X8>3.0478315353393555 X5>0.5 X8>3.561134457588196 X16<=0.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 26: X0<=0.5 X8>3.0478315353393555 X5>0.5 X8>3.561134457588196 X16>0.5 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 27: X0>0.5 X5<=0.5 X18<=0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 28: X0>0.5 X5<=0.5 X18>0.5 X4<=47.56235885620117 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 29: X0>0.5 X5<=0.5 X18>0.5 X4>47.56235885620117 X14<=0.4042994976043701 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 30: X0>0.5 X5<=0.5 X18>0.5 X4>47.56235885620117 X14>0.4042994976043701 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 31: X0>0.5 X5>0.5 X7<=2.7412874698638916 X4<=82.11330032348633 X3<=1.555619478225708 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 32: X0>0.5 X5>0.5 X7<=2.7412874698638916 X4<=82.11330032348633 X3>1.555619478225708 X18<=0.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 33: X0>0.5 X5>0.5 X7<=2.7412874698638916 X4<=82.11330032348633 X3>1.555619478225708 X18>0.5 X4<=67.4698257446289 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 34: X0>0.5 X5>0.5 X7<=2.7412874698638916 X4<=82.11330032348633 X3>1.555619478225708 X18>0.5 X4>67.4698257446289 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 35: X0>0.5 X5>0.5 X7<=2.7412874698638916 X4>82.11330032348633 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 36: X0>0.5 X5>0.5 X7>2.7412874698638916 X14<=0.025929000228643417 X2<=24.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 37: X0>0.5 X5>0.5 X7>2.7412874698638916 X14<=0.025929000228643417 X2>24.5 -> class 4 Covering: [0, 0, 0, 0, 1, 0, 0]\n",
      "Rule 38: X0>0.5 X5>0.5 X7>2.7412874698638916 X14>0.025929000228643417 X18<=0.5 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 39: X0>0.5 X5>0.5 X7>2.7412874698638916 X14>0.025929000228643417 X18>0.5 X4<=76.63050651550293 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 40: X0>0.5 X5>0.5 X7>2.7412874698638916 X14>0.025929000228643417 X18>0.5 X4>76.63050651550293 -> class 4 Covering: [0, 0, 0, 0, 1, 0, 0]\n",
      "-------------------\n",
      "Tree 2\n",
      "-------------------\n",
      "Rule 1: X2<=22.41487693786621 X6<=0.5 X7<=2.867648482322693 X0<=0.5 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 2: X2<=22.41487693786621 X6<=0.5 X7<=2.867648482322693 X0>0.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 3: X2<=22.41487693786621 X6<=0.5 X7>2.867648482322693 X3<=1.641668975353241 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 4: X2<=22.41487693786621 X6<=0.5 X7>2.867648482322693 X3>1.641668975353241 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 5: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4<=52.757150650024414 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 6: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15<=0.16500000655651093 X14<=1.2129384875297546 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 7: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15<=0.16500000655651093 X14>1.2129384875297546 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 8: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15>0.16500000655651093 X14<=1.0215539932250977 X3<=1.6312779784202576 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 9: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15>0.16500000655651093 X14<=1.0215539932250977 X3>1.6312779784202576 X13<=0.8715024888515472 X4<=78.46210479736328 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 10: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15>0.16500000655651093 X14<=1.0215539932250977 X3>1.6312779784202576 X13<=0.8715024888515472 X4>78.46210479736328 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 11: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15>0.16500000655651093 X14<=1.0215539932250977 X3>1.6312779784202576 X13>0.8715024888515472 X2<=21.5 X14<=0.5 X3<=1.6630069613456726 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 12: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15>0.16500000655651093 X14<=1.0215539932250977 X3>1.6312779784202576 X13>0.8715024888515472 X2<=21.5 X14<=0.5 X3>1.6630069613456726 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 13: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15>0.16500000655651093 X14<=1.0215539932250977 X3>1.6312779784202576 X13>0.8715024888515472 X2<=21.5 X14>0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 14: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15>0.16500000655651093 X14<=1.0215539932250977 X3>1.6312779784202576 X13>0.8715024888515472 X2>21.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 15: X2<=22.41487693786621 X6>0.5 X3<=1.7419909834861755 X4>52.757150650024414 X15>0.16500000655651093 X14>1.0215539932250977 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 16: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0<=0.5 X7<=2.1989980936050415 X2<=18.80814552307129 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 17: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0<=0.5 X7<=2.1989980936050415 X2>18.80814552307129 X5<=0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 18: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0<=0.5 X7<=2.1989980936050415 X2>18.80814552307129 X5>0.5 X15<=0.16500000655651093 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 19: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0<=0.5 X7<=2.1989980936050415 X2>18.80814552307129 X5>0.5 X15>0.16500000655651093 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 20: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0<=0.5 X7>2.1989980936050415 X2<=17.74343490600586 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 21: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0<=0.5 X7>2.1989980936050415 X2>17.74343490600586 X14<=0.6652285009622574 X13<=1.362149953842163 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 22: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0<=0.5 X7>2.1989980936050415 X2>17.74343490600586 X14<=0.6652285009622574 X13>1.362149953842163 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 23: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0<=0.5 X7>2.1989980936050415 X2>17.74343490600586 X14>0.6652285009622574 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 24: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0>0.5 X13<=2.28593248128891 -> class 4 Covering: [0, 0, 0, 0, 1, 0, 0]\n",
      "Rule 25: X2<=22.41487693786621 X6>0.5 X3>1.7419909834861755 X0>0.5 X13>2.28593248128891 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 26: X2>22.41487693786621 X18<=0.5 X4<=99.1512336730957 X2<=37.764068603515625 X8<=2.8398619890213013 X14<=0.04830700159072876 X4<=83.99717712402344 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 27: X2>22.41487693786621 X18<=0.5 X4<=99.1512336730957 X2<=37.764068603515625 X8<=2.8398619890213013 X14<=0.04830700159072876 X4>83.99717712402344 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 28: X2>22.41487693786621 X18<=0.5 X4<=99.1512336730957 X2<=37.764068603515625 X8<=2.8398619890213013 X14>0.04830700159072876 X3<=1.7061104774475098 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 29: X2>22.41487693786621 X18<=0.5 X4<=99.1512336730957 X2<=37.764068603515625 X8<=2.8398619890213013 X14>0.04830700159072876 X3>1.7061104774475098 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 30: X2>22.41487693786621 X18<=0.5 X4<=99.1512336730957 X2<=37.764068603515625 X8>2.8398619890213013 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 31: X2>22.41487693786621 X18<=0.5 X4<=99.1512336730957 X2>37.764068603515625 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 32: X2>22.41487693786621 X18<=0.5 X4>99.1512336730957 X1<=0.5 -> class 4 Covering: [0, 0, 0, 0, 1, 0, 0]\n",
      "Rule 33: X2>22.41487693786621 X18<=0.5 X4>99.1512336730957 X1>0.5 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 34: X2>22.41487693786621 X18>0.5 X15<=0.16500000655651093 X4<=92.63799285888672 X3<=1.5407634973526 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 35: X2>22.41487693786621 X18>0.5 X15<=0.16500000655651093 X4<=92.63799285888672 X3>1.5407634973526 X5<=0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 36: X2>22.41487693786621 X18>0.5 X15<=0.16500000655651093 X4<=92.63799285888672 X3>1.5407634973526 X5>0.5 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 37: X2>22.41487693786621 X18>0.5 X15<=0.16500000655651093 X4>92.63799285888672 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 38: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8<=2.5874840021133423 X7<=2.892235517501831 X0<=0.5 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 39: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8<=2.5874840021133423 X7<=2.892235517501831 X0>0.5 X2<=22.91815757751465 -> class 2 Covering: [0, 0, 1, 0, 0, 0, 0]\n",
      "Rule 40: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8<=2.5874840021133423 X7<=2.892235517501831 X0>0.5 X2>22.91815757751465 -> class 6 Covering: [0, 0, 0, 0, 0, 0, 1]\n",
      "Rule 41: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8<=2.5874840021133423 X7>2.892235517501831 X1<=0.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 42: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8<=2.5874840021133423 X7>2.892235517501831 X1>0.5 -> class 5 Covering: [0, 0, 0, 0, 0, 1, 0]\n",
      "Rule 43: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8>2.5874840021133423 X7<=2.815068483352661 X14<=0.869841992855072 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 44: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8>2.5874840021133423 X7<=2.815068483352661 X14>0.869841992855072 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 45: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8>2.5874840021133423 X7>2.815068483352661 X2<=25.51894474029541 -> class 3 Covering: [0, 0, 0, 1, 0, 0, 0]\n",
      "Rule 46: X2>22.41487693786621 X18>0.5 X15>0.16500000655651093 X8>2.5874840021133423 X7>2.815068483352661 X2>25.51894474029541 -> class 4 Covering: [0, 0, 0, 0, 1, 0, 0]\n",
      "-------------------\n",
      "Tree 3\n",
      "-------------------\n",
      "Rule 1: X3<=1.7446739673614502 X16<=0.5 X4<=55.5 X2<=23.5 X14<=0.06419699639081955 X7<=2.5 X9<=0.4950000196695328 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "Rule 2: X3<=1.7446739673614502 X16<=0.5 X4<=55.5 X2<=23.5 X14<=0.06419699639081955 X7<=2.5 X9>0.4950000196695328 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 3: X3<=1.7446739673614502 X16<=0.5 X4<=55.5 X2<=23.5 X14<=0.06419699639081955 X7>2.5 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 4: X3<=1.7446739673614502 X16<=0.5 X4<=55.5 X2<=23.5 X14>0.06419699639081955 -> class 0 Covering: [1, 0, 0, 0, 0, 0, 0]\n",
      "Rule 5: X3<=1.7446739673614502 X16<=0.5 X4<=55.5 X2>23.5 -> class 1 Covering: [0, 1, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rulesFile = \"RF_rules.rls\"\n",
    "previewFile(rootDir+rulesFile, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output displays a segment of the newly generated file, showcasing rules generated by each tree of the random forest algorithm. Remarkably, the rules generated appear to be quite similar within a single tree. This is entirely normal, as each tree operates independently and may converge on similar decision boundaries.\n",
    "\n",
    "With our set of rules generated and ready to go, let's move on the next chapter and explore the Fidex algorithm to find local rules for given samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local rules generation - Fidex\n",
    "\n",
    "Now we can generate local rules to explain the model's results. We can start with launching [Fidex](https://hes-xplain.github.io/documentation/algorithms/fidex/fidex/) on one test sample. This will generate a rule explaining the sample locally. It is called local because the algorithm searches a rule only for one sample.\n",
    "\n",
    "First of all, let's take a look at Fidex's arguments :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are located with respect to the root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Path to the file containing the train portion of the dataset\n",
      "--train_class_file <str>      Path to the file containing the train true classes of the dataset, not mandatory if classes are specified in train data file\n",
      "--train_pred_file <str>       Path to the file containing predictions on the train portion of the dataset\n",
      "--test_data_file <str>        Path to the file containing the test sample(s) data, prediction (if no --test_pred_file) and true class(if no --test_class_file)\n",
      "--test_pred_file <str>        Path to the file containing predictions on the test portion of the dataset\n",
      "--weights_file <str>          Path to the file containing the trained weights of the model (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Path to the file containing the trained rules to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "--rules_outfile <str>         Path to the file where the output rule(s) will be stored. If a .json extension is given, rules are saved in JSON format\n",
      "--nb_attributes <int [1,inf[> Number of attributes in the dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in the dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "-h --help                     Show this help message and exit\n",
      "--json_config_file <str>      Path to the JSON file that configures all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Path to the folder, based on main default folder dimlpfidex, containing all used files and where generated files will be saved. If a file name is specified with another option, its path will be relative to this root folder\n",
      "--test_class_file <str>       Path to the file containing the test true classes of the dataset. If at least --test_pred_file is specified, --test_data_file needs to have only test datas and eventually classes on same line (don't add --test_class_file in this case)\n",
      "--attributes_file <str>       Path to the file containing the labels of attributes and classes\n",
      "--stats_file <str>            Path to the file where statistics concerning the algorithm execution will be stored\n",
      "--console_file <str>          Path to the file where the terminal output will be redirected. If not specified, all output will be shown on your terminal\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Maximum number of iterations, also the maximum possible number of antecedents in a rule, it should be 25 when working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum number of samples covered by the generated rules (default: 2)\n",
      "--covering_strategy <bool>    Whether to use the covering strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find a Fidex rule when the covering is 1 and the covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during the covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Probability of dropping a dimension during rule extraction (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Probability of dropping a hyperplane during rule extraction (default: 0.0)\n",
      "--decision_threshold <float [0,1]>\n",
      "                              The decision threshold used for predictions, you need to specify the index of the positive class if you want to use it\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of the positive class for the usage of a decision threshold, index starts at 0\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in the staircase activation function (default: 50)\n",
      "--normalization_file <str>    Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]-inf,inf[>>\n",
      "                              Mean or median of each attribute index to be denormalized in the rules\n",
      "--sigmas <list<float ]-inf,inf[>>\n",
      "                              Standard deviation of each attribute index to be denormalized in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to be denormalized in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--seed <int [0,inf[>          Seed for random number generation, 0=random. Anything else than 0 is an arbitrary seed that can be reused to obtain the same randomly generated sequence and therefore getting same results (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidex(\"--train_data_file datanormTrain.txt --train_pred_file predTrain.out --train_class_file dataclass2Train.txt --test_data_file testSampleDataCombine.txt --nb_attributes 16 --nb_classes 2 --weights_file weights.wts --rules_outfile rules.rls --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = fidex(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the Fidex help output. We can observe that there are **required parameters**. Let's have a look at them:\n",
    "\n",
    "- `--train_data_file`: a file containing features from the training portion of the dataset\n",
    "- `--train_pred_file`: a file containing predictions from the training portion of the dataset\n",
    "- `--train_class_file`: a file containing classes from the training portion of the dataset\n",
    "- `--test_data_file`: a file containing samples to be used when generating a local rule\n",
    "- `--weights_file`: a file containing weights from a model training (in our case, we don't need it because we already have a `rules file` from the RF training)\n",
    "- `--rules_file`: a file containing the rules generated by a model training \n",
    "- `--rules_outfile`: a file name that will contain the output of the Fidex algorithm\n",
    "- `--nb_attributes`: the number of attributes present in the dataset\n",
    "- `--nb_classes`: the number of classes present in the dataset\n",
    "\n",
    "There are also optional arguments that we are going to use:\n",
    "- `--root_folder`: path defining the root directory where every other path specified in other arguments begins\n",
    "- `--attributes_file`: a file containing all attributes and class names\n",
    "\n",
    "All steps done until now will allow us to run the Fidex program. To see what happens, we launch it with just one sample. Therefore, we save the chosen test data sample in a file with its classes and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - train_data_file                                                    data/OCDDataset/train_dataset.txt\n",
      " - train_pred_file                                                        data/OCDDataset/predTrain.out\n",
      " - test_data_file                                                       data/OCDDataset/test_sample.txt\n",
      " - rules_file                                                              data/OCDDataset/RF_rules.rls\n",
      " - rules_outfile                                                        data/OCDDataset/fidex_rules.rls\n",
      " - root_folder                                                                         data/OCDDataset/\n",
      " - attributes_file                                                  data/OCDDataset/attributes_file.txt\n",
      " - nb_attributes                                                                                     20\n",
      " - nb_classes                                                                                         7\n",
      " - nb_quant_levels                                                                                   50\n",
      " - max_iterations                                                                                    10\n",
      " - min_covering                                                                                       2\n",
      " - max_failed_attempts                                                                               30\n",
      " - positive_class_index                                                                              -1\n",
      " - seed                                                                                               0\n",
      " - decision_threshold                                                                         -1.000000\n",
      " - hi_knot                                                                                     5.000000\n",
      " - dropout_hyp                                                                                 0.000000\n",
      " - dropout_dim                                                                                 0.000000\n",
      " - min_fidelity                                                                                1.000000\n",
      " - lowest_min_fidelity                                                                         0.750000\n",
      " - covering_strategy                                                                                  1\n",
      "End of Parameters list.\n",
      "\n",
      "Import files...\n",
      "\n",
      "Import time = 0.034163 sec\n",
      "Files imported\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Creation of hyperspace...\n",
      "Hyperspace created\n",
      "\n",
      "Searching for discriminating hyperplans...\n",
      "Initial fidelity : 0.121019\n",
      "Final fidelity : 1\n",
      "Discriminating hyperplans generated.\n",
      "\n",
      "\n",
      "Extracted rule :\n",
      "NCP<1.784425 TUE>=1.373035 TUE<1.785434 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.703333\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "\n",
      "Time without data import = 0.160236 sec\n",
      "\n",
      "Full execution time = 0.195073 sec\n"
     ]
    }
   ],
   "source": [
    "localRuleOutFileName = \"fidex_rules.rls\"\n",
    "trainClassesFile = \"train_classes.txt\"\n",
    "trainPredsFile = \"predTrain.out\" # generated by the RF\n",
    "testPredsFile = \"predTest.out\" # generated by the RF\n",
    "testSampleFile = \"test_sample.txt\"\n",
    "\n",
    "sampleSelected = 0\n",
    "assert(sampleSelected < nrows)\n",
    "\n",
    "\n",
    "# extract a sample to generate local rule\n",
    "testPreds = pd.read_csv(rootDir+testPredsFile, sep=\" \", header=None, index_col=None).iloc[:, :nclasses]\n",
    "sampleData = testds.iloc[sampleSelected, :nattributes].to_list()\n",
    "samplePred = testPreds.iloc[sampleSelected, :].to_list()\n",
    "sampleClasses = testds.iloc[sampleSelected, nattributes:].to_list()\n",
    "\n",
    "# write the sample, classes and predictions in the testSampleFile file (file writing format must be respected)\n",
    "with open(rootDir+testSampleFile, 'w') as f:\n",
    "    f.write(\" \".join(str(x) for x in sampleData) + '\\n')\n",
    "    f.write(\" \".join(str(x) for x in samplePred) + '\\n')\n",
    "    f.write(\" \".join(str(x) for x in sampleClasses) + '\\n')\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --test_data_file {testSampleFile}  \n",
    "        --rules_file {rulesFile} \n",
    "        --rules_outfile {localRuleOutFileName} \n",
    "        --nb_attributes {nattributes} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidex(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the algorithm shows us, in the terminal, a walkthrough of the process. At the end of it, you can observe the generated rule. Let's have a closer look at it by extracting the freshly written rule file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No decision threshold is used.\n",
      "\n",
      "Rule for sample 0 :\n",
      "\n",
      "NCP<1.784425 TUE>=1.373035 TUE<1.785434 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.703333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previewFile(rootDir+localRuleOutFileName, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output displays a preview of a rule generated by Fidex. Each rule includes various properties:\n",
    "- The index of the sample from which the rule has been generated\n",
    "- The rule itself, composed of a single or list of antecedents and the prediction\n",
    "- The number of samples, in the training dataset, covered by the rule\n",
    "- The fidelity of the rule according to the model's predictions\n",
    "- The accuracy of the rule\n",
    "- The confidence of the rule with its choices, concerning the prediction values\n",
    "\n",
    "These rules provide insights into the model's predictions for each sample, helping to explain its decision-making process.\n",
    "\n",
    "Next, we'll rerun Fidex with all test samples to generate a comprehensive set of rules for further analysis. Please note that this process may take some time depending on the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - train_data_file                                                    data/OCDDataset/train_dataset.txt\n",
      " - train_pred_file                                                        data/OCDDataset/predTrain.out\n",
      " - test_data_file                                                      data/OCDDataset/test_dataset.txt\n",
      " - test_pred_file                                                          data/OCDDataset/predTest.out\n",
      " - rules_file                                                              data/OCDDataset/RF_rules.rls\n",
      " - rules_outfile                                                        data/OCDDataset/fidex_rules.rls\n",
      " - root_folder                                                                         data/OCDDataset/\n",
      " - attributes_file                                                  data/OCDDataset/attributes_file.txt\n",
      " - nb_attributes                                                                                     20\n",
      " - nb_classes                                                                                         7\n",
      " - nb_quant_levels                                                                                   50\n",
      " - max_iterations                                                                                    10\n",
      " - min_covering                                                                                       2\n",
      " - max_failed_attempts                                                                               30\n",
      " - positive_class_index                                                                              -1\n",
      " - seed                                                                                               0\n",
      " - decision_threshold                                                                         -1.000000\n",
      " - hi_knot                                                                                     5.000000\n",
      " - dropout_hyp                                                                                 0.000000\n",
      " - dropout_dim                                                                                 0.000000\n",
      " - min_fidelity                                                                                1.000000\n",
      " - lowest_min_fidelity                                                                         0.750000\n",
      " - covering_strategy                                                                                  1\n",
      "End of Parameters list.\n",
      "\n",
      "Import files...\n",
      "\n",
      "Import time = 0.038787 sec\n",
      "Files imported\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Creation of hyperspace...\n",
      "Hyperspace created\n",
      "\n",
      "Computation of rule for sample 0 : \n",
      "\n",
      "Initial fidelity : 0.121019\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "NCP<1.784425 TUE>=1.373035 Age>=17 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.722\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 1 : \n",
      "\n",
      "Initial fidelity : 0.152866\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "NCP>=3.993853 Gender_Female>=0.5 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.6625\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 2 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=102.261555 Age>=33.095692 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.806667\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 3 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=102.261555 Age>=33.095692 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.84\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 4 : \n",
      "\n",
      "Initial fidelity : 0.184713\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "CALC>=0.33 NCP>=1.000771 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.6\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 5 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "NCP<2.205842 Age>=22.91216 Height>=1.763726 MTRANS_Automobile<0.5 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.784\n",
      "\n",
      "Result found after 4 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 6 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 0.5\n",
      "Fidelity is too low. Restarting fidex with a minimum covering of 1 and a minimum accepted fidelity of 1.\n",
      "Final fidelity : 1\n",
      "\n",
      "\n",
      "Extracted rule :\n",
      "Height>=1.889975 FCVC<2.006891 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 1\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.585\n",
      "\n",
      "The minimum covering of 2 is not achieved.\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 7 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Height<1.501305 MTRANS_Public_Transportation>=0.5 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.64\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 8 : \n",
      "\n",
      "Initial fidelity : 0.0955414\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=110.964508 Gender_Female>=0.5 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 12\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.946154\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 9 : \n",
      "\n",
      "Initial fidelity : 0.184713\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "CAEC>=0.665 Weight<96.462166 Weight>=56.5 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.62\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 10 : \n",
      "\n",
      "Initial fidelity : 0.121019\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "NCP<1.784425 TUE>=1.333872 Height>=1.551805 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.762\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 11 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=26.840654 Age<27.443615 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.656667\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 12 : \n",
      "\n",
      "Initial fidelity : 0.184713\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<90.5588 Weight>=67.479874 Weight<75.039795 MTRANS_Automobile>=0.5 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.72\n",
      "\n",
      "Result found after 4 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 13 : \n",
      "\n",
      "Initial fidelity : 0.0955414\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=127.181885 TUE>=0.098112 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 7\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.90625\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 14 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=22.918158 FCVC<2.168022 CH2O<1.022793 CAEC<0.33 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.643333\n",
      "\n",
      "Result found after 4 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 15 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=113.07732 Height>=1.806409 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 9\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.902\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 16 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=113.07732 Gender_Male>=0.5 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 18\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.924211\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 17 : \n",
      "\n",
      "Initial fidelity : 0.146497\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<44.347647 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.88\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 18 : \n",
      "\n",
      "Initial fidelity : 0.152866\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "MTRANS_Walking>=0.5 FCVC>=2.006891 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.736667\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 19 : \n",
      "\n",
      "Initial fidelity : 0.146497\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<44.347647 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.9\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 20 : \n",
      "\n",
      "Initial fidelity : 0.184713\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC<2.104439 Age<21.978546 Height<1.648705 Weight>=49.5 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 8\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.728889\n",
      "\n",
      "Result found after 4 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 21 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=113.07732 FCVC<2.006891 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.905\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 22 : \n",
      "\n",
      "Initial fidelity : 0.146497\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<44.347647 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.857143\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 23 : \n",
      "\n",
      "Initial fidelity : 0.152866\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<67.479874 Age>=22.461605 Height>=1.5301 Age>=23.018863 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.606667\n",
      "\n",
      "Result found after 4 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 24 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 0.5\n",
      "Fidelity is too low. Restarting fidex with a minimum covering of 1 and a minimum accepted fidelity of 1.\n",
      "Final fidelity : 1\n",
      "\n",
      "\n",
      "Extracted rule :\n",
      "FCVC<2.006891 Age>=22.324896 Age<22.797991 CH2O>=1.152455 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 1\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.55\n",
      "\n",
      "The minimum covering of 2 is not achieved.\n",
      "Result found after 4 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 25 : \n",
      "\n",
      "Initial fidelity : 0.121019\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Height<1.610623 Weight>=74.236595 CH2O>=1.019656 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.804286\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 26 : \n",
      "\n",
      "Initial fidelity : 0.184713\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC<1.9446 CH2O>=2.039525 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 5\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.788333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 27 : \n",
      "\n",
      "Initial fidelity : 0.152866\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<67.479874 Weight>=63.5 CAEC>=0.33 -> OLD_Normal_Weight\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.758\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 28 : \n",
      "\n",
      "Initial fidelity : 0.0955414\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=129.279129 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 7\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.92375\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 29 : \n",
      "\n",
      "Initial fidelity : 0.0955414\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=110.964508 Gender_Male<0.5 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 12\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.944615\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 30 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=112.144943 TUE<0.064197 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 5\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.883333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 31 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FAVC<0.5 Height<1.601353 CH2O>=1.717416 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.566667\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 32 : \n",
      "\n",
      "Initial fidelity : 0.184713\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "CAEC<0.165 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.805\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 33 : \n",
      "\n",
      "Initial fidelity : 0.0955414\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=129.279129 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 7\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.9025\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 34 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FAVC<0.5 Weight>=78.500061 CH2O<2.006803 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.64\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 35 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=113.07732 Gender_Female<0.5 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 18\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.924737\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 36 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=113.07732 Gender_Male>=0.5 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 18\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.924211\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 37 : \n",
      "\n",
      "Initial fidelity : 0.184713\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "FCVC<2.104439 MTRANS_Automobile>=0.5 CH2O<1.276819 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.715\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 38 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=102.261555 Height>=1.836236 Age>=18.371794 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 7\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.8175\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 39 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "NCP<2.205842 Height>=1.686201 Height<1.70611 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.61\n",
      "\n",
      "Result found after 3 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 40 : \n",
      "\n",
      "Initial fidelity : 0.146497\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<44.347647 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.898571\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 41 : \n",
      "\n",
      "Initial fidelity : 0.140127\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=38.214985 Height<1.696938 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.723333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 42 : \n",
      "\n",
      "Initial fidelity : 0.152866\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<67.479874 Weight>=65.445974 -> OLD_Normal_Weight\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.718\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 43 : \n",
      "\n",
      "Initial fidelity : 0.152866\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "MTRANS_Walking>=0.5 CH2O<1.000272 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.66\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 44 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=98.393711 NCP>=3.04356 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.773333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 45 : \n",
      "\n",
      "Initial fidelity : 0.121019\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Age>=36.57976 Height<1.668101 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.603333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 46 : \n",
      "\n",
      "Initial fidelity : 0.152866\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "SCC>=0.5 CALC<0.165 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.583333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 47 : \n",
      "\n",
      "Initial fidelity : 0.0955414\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=102.000061 Height<1.625482 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.9275\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 48 : \n",
      "\n",
      "Initial fidelity : 0.146497\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<52.610193 FCVC<1.594045 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.743333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 49 : \n",
      "\n",
      "Initial fidelity : 0.184713\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "CALC>=0.33 NCP>=1.000771 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.583333\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 50 : \n",
      "\n",
      "Initial fidelity : 0.159236\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=113.07732 FCVC<1.980306 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.91\n",
      "\n",
      "Result found after 2 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 51 : \n",
      "\n",
      "Initial fidelity : 0.0955414\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight>=129.279129 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 7\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.915\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "Computation of rule for sample 52 : \n",
      "\n",
      "Initial fidelity : 0.146497\n",
      "Final fidelity : 1\n",
      "\n",
      "Extracted rule :\n",
      "Weight<44.347647 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 6\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.865714\n",
      "\n",
      "Result found after 1 iterations.\n",
      "-------------------------------------------------\n",
      "\n",
      "Time without data import = 0.59256 sec\n",
      "\n",
      "Full execution time = 0.634581 sec\n"
     ]
    }
   ],
   "source": [
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --test_data_file {testDataFile}  \n",
    "        --test_pred_file {testPredsFile}\n",
    "        --rules_file {rulesFile} \n",
    "        --rules_outfile {localRuleOutFileName} \n",
    "        --nb_attributes {nattributes} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_classes {nclasses}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidex(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fidex algorithm generated a rule file, let's observe what is inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No decision threshold is used.\n",
      "\n",
      "Rule for sample 0 :\n",
      "\n",
      "NCP<1.784425 TUE>=1.373035 Age>=17 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.722\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 1 :\n",
      "\n",
      "NCP>=3.993853 Gender_Female>=0.5 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.6625\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 2 :\n",
      "\n",
      "Weight>=102.261555 Age>=33.095692 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.806667\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 3 :\n",
      "\n",
      "Weight>=102.261555 Age>=33.095692 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.84\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 4 :\n",
      "\n",
      "CALC>=0.33 NCP>=1.000771 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.6\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 5 :\n",
      "\n",
      "NCP<2.205842 Age>=22.91216 Height>=1.763726 MTRANS_Automobile<0.5 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.784\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 6 :\n",
      "\n",
      "Height>=1.889975 FCVC<2.006891 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 1\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.585\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 7 :\n",
      "\n",
      "Height<1.501305 MTRANS_Public_Transportation>=0.5 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.64\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 8 :\n",
      "\n",
      "Weight>=110.964508 Gender_Female>=0.5 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 12\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.946154\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "Rule for sample 9 :\n",
      "\n",
      "CAEC>=0.665 Weight<96.462166 Weight>=56.5 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.62\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fidexRulesOutfile = \"fidex_rules.rls\"\n",
    "previewFile(rootDir+fidexRulesOutfile, 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the output is very similar to the single sample test, the only difference is the amount of rules generated, which is proportional to the number of samples.\n",
    "\n",
    "Running Fidex with all samples provides a comprehensive set of rules adapted to every sample given. These rules are useful for understanding how different factors influence the model's predictions for various samples.\n",
    "\n",
    "In the next chapter, we will move on to global ruleSet generation using FidexGloRules. This will help us understand the overall behavior of the model by generating a set of global rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global ruleSet generation - FidexGlo\n",
    "We have seen how to compute a rule that explains the decision of the model for a specific sample with the Fidex algorithm. But how could we get a general set of rules that characterizes the whole train dataset? Using the [FidexGloRules](https://hes-xplain.github.io/documentation/algorithms/fidex/fidexglorules) algorithm, it is possible to achieve this.\n",
    "\n",
    "A global ruleset is a collection of rules that explains the model's decision for each sample present on the training portion of the dataset. Let's have a look at the fidexGloRules arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are located with respect to the root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--train_data_file <str>       Path to the file containing the train portion of the dataset\n",
      "--train_class_file <str>      Path to the file containing the train true classes of the dataset, not mandatory if classes are specified in train data file\n",
      "--train_pred_file <str>       Path to the file containing predictions on the train portion of the dataset\n",
      "--weights_file <str>          Path to the file containing the trained weights of the model (not mandatory if a rules file is given with --rules_file)\n",
      "--rules_file <str>            Path to the file containing the trained rules to be converted to hyperlocus (not mandatory if a weights file is given with --weights_file)\n",
      "--global_rules_outfile <str>  Path to the file where the output rule(s) will be stored. If a .json extension is given, rules are saved in JSON format\n",
      "--heuristic <int [1,3]>       Heuristic 1: optimal fidexGlo, 2: fast fidexGlo 3: very fast fidexGlo. (Faster algorithms are less efficient)\n",
      "--nb_attributes <int [1,inf[> Number of attributes in the dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in the dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "-h --help                     Show this help message and exit\n",
      "--json_config_file <str>      Path to the JSON file that configures all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Path to the folder, based on main default folder dimlpfidex, containing all used files and where generated files will be saved. If a file name is specified with another option, its path will be relative to this root folder\n",
      "--attributes_file <str>       Path to the file containing the labels of attributes and classes\n",
      "--console_file <str>          Path to the file where the terminal output will be redirected. If not specified, all output will be shown on your terminal\n",
      "--max_iterations <int [1,inf[>\n",
      "                              Maximum number of iterations, also the maximum possible number of antecedents in a rule, it should be 25 when working with images (default: 10)\n",
      "--min_covering <int [1,inf[>  Minimum number of samples covered by the generated rules (default: 2)\n",
      "--covering_strategy <bool>    Whether to use the covering strategy : if no rule is found with min_covering, find best rule with best covering using dichotomic search. Decreases min_fidelity if needed (default: True)\n",
      "--max_failed_attempts <int [0,inf[>\n",
      "                              Maximum number of failed attempts to find a Fidex rule when the covering is 1 and the covering strategy is used (default: 30)\n",
      "--min_fidelity <float [0,1]>  Minimal rule fidelity accepted when generating a rule (default: 1.0)\n",
      "--lowest_min_fidelity <float [0,1]>\n",
      "                              Minimal min_fidelity to which we agree to go down during the covering_strategy (default: 0.75)\n",
      "--dropout_dim <float [0,1]>   Probability of dropping a dimension during rule extraction (default: 0.0)\n",
      "--dropout_hyp <float [0,1]>   Probability of dropping a hyperplane during rule extraction (default: 0.0)\n",
      "--decision_threshold <float [0,1]>\n",
      "                              The decision threshold used for predictions, you need to specify the index of the positive class if you want to use it\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of the positive class for the usage of a decision threshold, index starts at 0\n",
      "--nb_quant_levels <int [3,inf[>\n",
      "                              Number of stairs in the staircase activation function (default: 50)\n",
      "--normalization_file <str>    Path to the file containing the mean and standard deviation of some attributes. Used to denormalize the rules if specified\n",
      "--mus <list<float ]-inf,inf[>>\n",
      "                              Mean or median of each attribute index to be denormalized in the rules\n",
      "--sigmas <list<float ]-inf,inf[>>\n",
      "                              Standard deviation of each attribute index to be denormalized in the rules\n",
      "--normalization_indices <list<int [0,nb_attributes-1]>>\n",
      "                              Attribute indices to be denormalized in the rules, only used when no normalization_file is given, index starts at 0 (default: [0,...,nb_attributes-1])\n",
      "--nb_threads <int [1,nb_cores]>\n",
      "                              Number of threads used for computing the algorithm, 1=sequential execution (default: 1)\n",
      "--seed <int [0,inf[>          Seed for random number generation, 0=random. Anything else than 0 is an arbitrary seed that can be reused to obtain the same randomly generated sequence and therefore getting same results (default: 0)\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidexGloRules(\"--train_data_file datanormTrain.txt --train_pred_file predTrain.out --train_class_file dataclass2Train.txt --weights_file weights.wts --nb_attributes 16 --nb_classes 2 --heuristic 1 --global_rules_outfile globalRules.rls --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = fidexGloRules(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, there are required parameters very similar to the `Fidex` algorithm, there are many optional arguments that you can use to customize the behavior of the algorithm. Let's have a look at some of them:\n",
    "\n",
    "- `--heuristic`: various ways to run the algorithm, these ways aim to increase execution speed. But also has a performance impact on results.\n",
    "- `--nb_threads`: number of threads used to compute the algorithm. Accelerate the process.\n",
    "- `--min_covering`: minimal number of samples a rule must cover\n",
    "- `--max_failed_attempts`: maximum failed attempts allowed when generating a rule\n",
    "- `--min_fidelity`: minimal fidelity allowed when generating a rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - train_data_file                                                    data/OCDDataset/train_dataset.txt\n",
      " - train_pred_file                                                        data/OCDDataset/predTrain.out\n",
      " - rules_file                                                              data/OCDDataset/RF_rules.rls\n",
      " - global_rules_outfile                                         data/OCDDataset/fidexGloRules_rules.rls\n",
      " - root_folder                                                                         data/OCDDataset/\n",
      " - attributes_file                                                  data/OCDDataset/attributes_file.txt\n",
      " - nb_attributes                                                                                     20\n",
      " - nb_classes                                                                                         7\n",
      " - nb_quant_levels                                                                                   50\n",
      " - heuristic                                                                                          1\n",
      " - max_iterations                                                                                    10\n",
      " - min_covering                                                                                       2\n",
      " - max_failed_attempts                                                                               30\n",
      " - nb_threads                                                                                         2\n",
      " - positive_class_index                                                                              -1\n",
      " - seed                                                                                               0\n",
      " - decision_threshold                                                                         -1.000000\n",
      " - hi_knot                                                                                     5.000000\n",
      " - dropout_hyp                                                                                 0.000000\n",
      " - dropout_dim                                                                                 0.000000\n",
      " - min_fidelity                                                                                1.000000\n",
      " - lowest_min_fidelity                                                                         0.750000\n",
      " - covering_strategy                                                                                  1\n",
      "End of Parameters list.\n",
      "\n",
      "Importing files...\n",
      "Files imported\n",
      "\n",
      "Creation of hyperspace...\n",
      "Hyperspace created.\n",
      "\n",
      "Computing fidex rules...\n",
      "\n",
      "Thread #0 initialized, please wait for it to be done.\n",
      "Thread #1 initialized, please wait for it to be done.\n",
      "Estimated total execution time after 1 sample(s): 0 hours, 0 minutes, 0 seconds.\n",
      "Estimated total execution time after 10 sample(s): 0 hours, 0 minutes, 0 seconds.\n",
      "Estimated total execution time after 100 sample(s): 0 hours, 0 minutes, 0 seconds.\n",
      "Thread #0 ended 79 iterations in 0.444785 seconds.\n",
      "Thread #1 ended 78 iterations in 0.444718 seconds.\n",
      "\n",
      "157 rules created.\n",
      "Number of samples with lower covering than 2 is 1\n",
      "Number of rules not found is 0\n",
      "Fidex rules computed\n",
      "Computing global ruleset...\n",
      "53 rules selected.\n",
      "Global ruleset Computed.\n",
      "\n",
      "heuristic #1 ended in 0.446075 sec\n",
      "\n",
      "Rules extraction...\n",
      "Mean covering size per rule : 3.92453\n",
      "Mean number of antecedents per rule : 2.67925\n",
      "\n",
      "Full execution time = 0.447505 sec\n"
     ]
    }
   ],
   "source": [
    "heuristic = 1\n",
    "nthreads = 2\n",
    "globalRulesOutfile = \"fidexGloRules_rules.rls\"\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir} \n",
    "        --nb_threads {nthreads} \n",
    "        --train_data_file {trainDataFile} \n",
    "        --train_pred_file {trainPredsFile} \n",
    "        --rules_file {rulesFile} \n",
    "        --attributes_file {attributesFile} \n",
    "        --nb_attributes {nattributes} \n",
    "        --nb_classes {nclasses} \n",
    "        --heuristic {heuristic} \n",
    "        --global_rules_outfile {globalRulesOutfile}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidexGloRules(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm generated a file that we're going to partially observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rules : 53, mean sample covering number per rule : 3.924528, mean number of antecedents per rule : 2.679245\n",
      "No decision threshold is used.\n",
      "\n",
      "Rule 1: Weight>=113.07732 Gender_Male>=0.5 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 18\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.924444\n",
      "\n",
      "Rule 2: Weight>=102.000061 Gender_Female>=0.5 -> OLD_Obesity_Type_III\n",
      "   Train Covering size : 15\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.936667\n",
      "\n",
      "Rule 3: Weight<53.543285 Height>=1.650095 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 12\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.854167\n",
      "\n",
      "Rule 4: Weight<61.931969 Height>=1.700091 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 11\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.862727\n",
      "\n",
      "Rule 5: FCVC<2.104439 Age<21.978546 Age>=20.497272 Weight<78.764286 Weight>=53.04331 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 9\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.798889\n",
      "\n",
      "Rule 6: NCP<1.784425 Weight>=80.363098 TUE>=0.28424 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 8\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.84375\n",
      "\n",
      "Rule 7: Weight<47.313856 -> OLD_Insufficient_Weight\n",
      "   Train Covering size : 8\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.87\n",
      "\n",
      "Rule 8: Weight<67.479874 Weight>=63.5 Gender_Female<0.5 -> OLD_Normal_Weight\n",
      "   Train Covering size : 5\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.816\n",
      "\n",
      "Rule 9: Weight<67.479874 Weight>=52.610193 Weight<58.739519 TUE<0.000665 -> OLD_Normal_Weight\n",
      "   Train Covering size : 5\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.76\n",
      "\n",
      "Rule 10: NCP>=3.091391 Weight>=64.806358 Height>=1.749094 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 5\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.814\n",
      "\n",
      "Rule 11: TUE>=1.996095 FCVC>=2.006891 -> OLD_Normal_Weight\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.775\n",
      "\n",
      "Rule 12: Weight<90.5588 Weight>=67.479874 Weight<70.979874 Gender_Male<0.5 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.79\n",
      "\n",
      "Rule 13: FCVC<2.104439 CH2O>=2.284032 FAF>=1.000467 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7925\n",
      "\n",
      "Rule 14: Weight>=112.144943 FAF<0.000648 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.8875\n",
      "\n",
      "Rule 15: Weight<67.479874 Weight>=63.5 FCVC<2.006891 -> OLD_Normal_Weight\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7725\n",
      "\n",
      "Rule 16: Weight<67.479874 Weight>=65.445974 -> OLD_Normal_Weight\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7575\n",
      "\n",
      "Rule 17: Weight<90.5588 Weight>=67.479874 Weight<74.011059 TUE<0.000665 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.79\n",
      "\n",
      "Rule 18: Age>=33.345119 CH2O>=1.895643 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.7675\n",
      "\n",
      "Rule 19: NCP<2.205842 NCP>=1.784425 Height>=1.65391 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 4\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.76\n",
      "\n",
      "Rule 20: FAVC<0.5 Weight>=78.500061 FAF>=0.000648 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.71\n",
      "\n",
      "Rule 21: FCVC<2.104439 MTRANS_Automobile>=0.5 Age<24.010372 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.783333\n",
      "\n",
      "Rule 22: CAEC>=0.33 Age<19.017016 Height>=1.750634 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.77\n",
      "\n",
      "Rule 23: Age<17.135217 FAF<0.000648 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.753333\n",
      "\n",
      "Rule 24: Age>=26.840654 Height>=1.767671 Weight<93.845119 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.82\n",
      "\n",
      "Rule 25: Weight>=110.14399 FCVC<1.821474 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.9\n",
      "\n",
      "Rule 26: MTRANS_Walking>=0.5 Age<17.135217 -> OLD_Normal_Weight\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.766667\n",
      "\n",
      "Rule 27: FAF>=2.015764 FAF<2.285932 Height>=1.606669 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 3\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.746667\n",
      "\n",
      "Rule 28: Weight<67.479874 Age>=22.461605 FHWO<0.5 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.71\n",
      "\n",
      "Rule 29: NCP<1.784425 Weight>=78.044788 Height<1.583925 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.785\n",
      "\n",
      "Rule 30: FCVC<2.104439 FCVC>=2.006891 CH2O<1.082031 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.76\n",
      "\n",
      "Rule 31: Height>=1.8 Height<1.817666 MTRANS_Public_Transportation<0.5 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.71\n",
      "\n",
      "Rule 32: FAVC<0.5 Height<1.570581 CALC<0.165 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.67\n",
      "\n",
      "Rule 33: Weight>=102.261555 Age>=30.041124 Weight<102.956036 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.865\n",
      "\n",
      "Rule 34: SCC>=0.5 TUE>=1.000703 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.69\n",
      "\n",
      "Rule 35: FHWO<0.5 CH2O<1.038958 FAF>=0.000648 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.88\n",
      "\n",
      "Rule 36: CH2O>=2.990802 Height>=1.834013 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.735\n",
      "\n",
      "Rule 37: CAEC>=0.665 Weight>=96.462166 FCVC<2.006891 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.625\n",
      "\n",
      "Rule 38: FCVC<2.31316 MTRANS_Automobile>=0.5 Weight<75.000061 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.78\n",
      "\n",
      "Rule 39: CALC>=0.33 MTRANS_Public_Transportation>=0.5 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.705\n",
      "\n",
      "Rule 40: NCP<2.911492 NCP>=2.878311 Height<1.846471 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.745\n",
      "\n",
      "Rule 41: FAVC<0.5 NCP<1.135812 FHWO>=0.5 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.685\n",
      "\n",
      "Rule 42: NCP<1.784425 Weight>=80.363098 NCP>=1.203211 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.825\n",
      "\n",
      "Rule 43: Weight<67.479874 CH2O>=2.907647 CALC>=0.165 -> OLD_Normal_Weight\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.73\n",
      "\n",
      "Rule 44: NCP<2.911492 NCP>=2.638301 NCP<2.783169 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.765\n",
      "\n",
      "Rule 45: Age>=29.433769 Age<30.041124 MTRANS_Automobile>=0.5 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.63\n",
      "\n",
      "Rule 46: Weight>=80.409042 Age<18.500729 Gender_Male<0.5 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.725\n",
      "\n",
      "Rule 47: Height<1.501305 Weight>=55.5 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.73\n",
      "\n",
      "Rule 48: Weight>=102.261555 Age>=33.095692 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.86\n",
      "\n",
      "Rule 49: Age>=36.57976 Height<1.562151 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.73\n",
      "\n",
      "Rule 50: SMOKE>=0.5 CH2O>=1.529187 -> OLD_Overweight_Level_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.715\n",
      "\n",
      "Rule 51: NCP<2.623999 NCP>=2.28336 FCVC<2.052052 -> OLD_Obesity_Type_I\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.79\n",
      "\n",
      "Rule 52: Weight>=98.393711 Weight<101.259975 -> OLD_Obesity_Type_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.825\n",
      "\n",
      "Rule 53: Age>=26.840654 Age<27.443615 -> OLD_Overweight_Level_II\n",
      "   Train Covering size : 2\n",
      "   Train Fidelity : 1\n",
      "   Train Accuracy : 1\n",
      "   Train Confidence : 0.745\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previewFile(rootDir+globalRulesOutfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The algorithm result is subject to randomness as it uses random processes to compute. Results may differ between executions.*\n",
    "\n",
    "You can observe the rules are ordered by their covering size. The first rule is the one that best describes the training portion of the dataset.\n",
    "\n",
    "Here's a given rule (can be unrelated to execution due to randomness) we are going to analyze:\n",
    "\n",
    "```md\n",
    "Rule 1: Weight>=101.258713 Gender_Female>=0.5 -> OLD_Obesity_Type_III\n",
    "   Train Covering size : 25\n",
    "   Train Fidelity : 1\n",
    "   Train Accuracy : 1\n",
    "   Train Confidence : 0.9852\n",
    "```\n",
    "\n",
    "This rule means the model is **98% sure** someone could suffer from `Type 3 obesity` if his/her weight is above or equal to `~101.2 kg` and if he/she is, biologically speaking, a female. The rule is also **100% fidel** according to the model's predictions and is **100% accurate** concerning the training portion of the dataset.\n",
    "\n",
    "To get statistics on the test portion of the dataset, let's execute the [fidexGloStats](https://hes-xplain.github.io/documentation/algorithms/fidex/fidexglostats) algorithm. Beginning with an overview of the arguments of the program: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Warning! The files are located with respect to the root folder dimlpfidex.\n",
      "The arguments can be specified in the command or in a json configuration file with --json_config_file your_config_file.json.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Required parameters:\n",
      "\n",
      "--test_data_file <str>        Path to the file containing the test portion of the dataset\n",
      "--test_class_file <str>       Path to the file containing the test true classes of the dataset, not mandatory if classes are specified in test data file\n",
      "--test_pred_file <str>        Path to the file containing predictions on the test portion of the dataset\n",
      "--global_rules_file <str>     Path to the file containing the global rules obtained with fidexGloRules algorithm.\n",
      "--nb_attributes <int [1,inf[> Number of attributes in the dataset\n",
      "--nb_classes <int [2,inf[>    Number of classes in the dataset\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Optional parameters: \n",
      "\n",
      "-h --help                     Show this help message and exit\n",
      "--json_config_file <str>      Path to the JSON file that configures all parameters. If used, this must be the sole argument and must specify the file's relative path\n",
      "--root_folder <str>           Path to the folder, based on main default folder dimlpfidex, containing all used files and where generated files will be saved. If a file name is specified with another option, its path will be relative to this root folder\n",
      "--global_rules_outfile <str>  Path to the file where the output global rules will be stored with stats on test set, if you want to compute those statistics. If a .json extension is given, rules are saved in JSON format\n",
      "--attributes_file <str>       Path to the file containing the labels of attributes and classes> Mandatory if rules file contains attribute names, if not, do not add it\n",
      "--stats_file <str>            Path to the file where statistics of the global ruleset will be stored\n",
      "--console_file <str>          Path to the file where the terminal output will be redirected. If not specified, all output will be shown on your terminal\n",
      "--positive_class_index <int [0,nb_classes-1]>\n",
      "                              Index of the positive class to compute true/false positive/negative rates, index starts at 0. If it is specified in the rules file, it has to be the same value.\n",
      "\n",
      "----------------------------\n",
      "\n",
      "Execution example :\n",
      "\n",
      "fidex.fidexGloStats(\"--test_data_file datanormTest.txt --test_pred_file predTest.out --test_class_file dataclass2Test.txt --global_rules_file globalRules.rls --nb_attributes 16 --nb_classes 2 --stats_file stats.txt --root_folder dimlp/datafiles\")\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = fidexGloStats(\"--help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, the required arguments are pretty much the same as previous executions. The only one that differs is `--global_rules_file` which simply asks to input the global rule file to compute statistics. Let's try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters list:\n",
      " - test_data_file                                                      data/OCDDataset/test_dataset.txt\n",
      " - test_pred_file                                                          data/OCDDataset/predTest.out\n",
      " - global_rules_file                                            data/OCDDataset/fidexGloRules_rules.rls\n",
      " - root_folder                                                                         data/OCDDataset/\n",
      " - attributes_file                                                  data/OCDDataset/attributes_file.txt\n",
      " - stats_file                                                              data/OCDDataset/RF_stats.txt\n",
      " - nb_attributes                                                                                     20\n",
      " - nb_classes                                                                                         7\n",
      " - positive_class_index                                                                              -1\n",
      "End of Parameters list.\n",
      "\n",
      "Importing files...\n",
      "\n",
      "Data imported.\n",
      "\n",
      "Compute statistics...\n",
      "\n",
      "Global statistics of the rule set : \n",
      "Number of rules : 53, mean sample covering number per rule : 3.924528, mean number of antecedents per rule : 2.679245\n",
      "\n",
      "Statistics with a test set of 53 samples :\n",
      "\n",
      "No decision threshold is used.\n",
      "No positive index class is used.\n",
      "The global rule fidelity rate is : 0.830189\n",
      "The global rule accuracy is : 0.792453\n",
      "The explainability rate (when we can find one or more rules, either correct ones or activated ones which all agree on the same class) is : 0.905660\n",
      "The default rule rate (when we can't find any rule activated for a sample) is : 0.018868\n",
      "The mean number of correct(fidel) activated rules per sample is : 1.018868\n",
      "The mean number of wrong(not fidel) activated rules per sample is : 0.886792\n",
      "The model test accuracy is : 0.811321\n",
      "The model test accuracy when rules and model agree is : 0.886364\n",
      "The model test accuracy when activated rules and model agree is : 0.883721\n",
      "\n",
      "Full execution time = 0.020082 sec\n"
     ]
    }
   ],
   "source": [
    "statsOutfileName = \"RF_stats.txt\"\n",
    "\n",
    "args = f\"\"\"\n",
    "        --root_folder {rootDir}\n",
    "        --test_data_file {testDataFile}\n",
    "        --test_pred_file {testPredsFile}\n",
    "        --global_rules_file {globalRulesOutfile}\n",
    "        --nb_attributes {nattributes}\n",
    "        --nb_classes {nclasses}\n",
    "        --attributes_file {attributesFile}\n",
    "        --stats_file {statsOutfileName}\n",
    "        \"\"\"\n",
    "\n",
    "status = fidexGloStats(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution of the algorithm generated a file that we named `RF_stats.txt` containing pretty much the same feedback as the program output. That being said, let's have a look inside the generated file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global statistics of the rule set : \n",
      "Number of rules : 53, mean sample covering number per rule : 3.924528, mean number of antecedents per rule : 2.679245\n",
      "\n",
      "Statistics with a test set of 53 samples :\n",
      "\n",
      "No decision threshold is used.\n",
      "No positive index class is used.\n",
      "The global rule fidelity rate is : 0.830189\n",
      "The global rule accuracy is : 0.792453\n",
      "The explainability rate (when we can find one or more rules, either correct ones or activated ones which all agree on the same class) is : 0.905660\n",
      "The default rule rate (when we can't find any rule activated for a sample) is : 0.018868\n",
      "The mean number of correct(fidel) activated rules per sample is : 1.018868\n",
      "The mean number of wrong(not fidel) activated rules per sample is : 0.886792\n",
      "The model test accuracy is : 0.811321\n",
      "The model test accuracy when rules and model agree is : 0.886364\n",
      "The model test accuracy when activated rules and model agree is : 0.883721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previewFile(rootDir+statsOutfileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the program shows various metrics, let's have a look at them individually:\n",
    "\n",
    "- `Global statistics`: Several values expressing general information about the ruleset.\n",
    "- `Decision threshold`: Value used to define a threshold where a class is considered as true. In this case, it's written that `no decision threshold is used`.\n",
    "- `Positive index class`: This value means which class is considered as the positive one. If no threshold is used, this cannot be used, like in this case.\n",
    "- `Global rule fidelity rate`: Expressing whether the ruleset accurately reflects the model's predictions.\n",
    "- `Global rule accuracy`: Proportion of correct predictions made by the ruleset.\n",
    "- `Explainability rate`: Proportion of the samples that could be explained by one or more rules.\n",
    "- `Default rule rate`: Proportion of samples that could not be explained by a rule offered by the ruleset.\n",
    "- `Mean number of correct activated rules`: Average number of correct rules activated per sample.\n",
    "- `Mean number of wrong activated rules`: Average number of incorrect rules activated per sample.\n",
    "- `Model test accuracy`: Accuracy of the model on the test dataset\n",
    "- `Model test accuracy when rules agree`: Accuracy of the model on test samples where the ruleset and model predictions agree.\n",
    "- `Model test accuracy when activated rules agree`: Accuracy when at least one activated rule agrees with the model's prediction.\n",
    "\n",
    "With this program, you can have a general overview of the quality of the ruleset.\n",
    "\n",
    "With the generation of local and global rules using the Fidex algorithms, we have a clearer view of how our model makes predictions. These rules help us understand the model's decisions, making it more transparent. Now, let's wrap up our findings and discuss the importance of explainable AI in the final chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explored explainable AI using Random Forests and the Fidex family of algorithms. We prepared our dataset, trained a Random Forest model, and examined the generated rules. We used `Fidex` to create local rules for individual sample explanations and `FidexGloRules` to generate a global ruleset for the entire training dataset. Finally, we evaluated the ruleset with `FidexGloStats`, providing insights into the model's accuracy, fidelity, and explainability.\n",
    "\n",
    "This process demonstrated how explainable AI techniques can clarify complex models, making them more transparent and trustworthy. By understanding our model's decision-making process, we can ensure better, more reliable outcomes in various applications. Using Random Forests with Fidex offers a balanced approach to building interpretable and effective AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "HES-XPLAIN: [website](https://hes-xplain.github.io/), [Github page](https://github.com/HES-XPLAIN)\n",
    "\n",
    "Dataset: [source](https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster), [author](https://www.kaggle.com/aravindpcoder)\n",
    "\n",
    "Dimlpfidex: [Github repository](https://github.com/HES-XPLAIN/dimlpfidex), [documentation](https://hes-xplain.github.io/documentation/overview/)\n",
    "\n",
    "Algorithms: [randomForest](https://hes-xplain.github.io/documentation/algorithms/training-methods/randforeststrn/), [Fidex](https://hes-xplain.github.io/documentation/algorithms/fidex/fidex/), [FidexGloRules](https://hes-xplain.github.io/documentation/algorithms/fidex/fidexglorules), [FidexGloStats](https://hes-xplain.github.io/documentation/algorithms/fidex/fidexglostats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
